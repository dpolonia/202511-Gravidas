# Tutorial Completo: Testando o Pipeline do Zero

## ğŸ¯ Objetivo

Este tutorial vai guiÃ¡-lo passo a passo para testar todo o pipeline de synthetic gravidas, desde a configuraÃ§Ã£o inicial atÃ© a geraÃ§Ã£o de entrevistas e anÃ¡lise de resultados.

**Tempo estimado:** 30-60 minutos para teste completo
**Custo estimado:** ~$3-5 USD para teste com 10 personas

---

## ğŸ“‹ PrÃ©-requisitos

### Verificar InstalaÃ§Ãµes

```bash
# 1. Python (versÃ£o 3.11+)
python --version
# Deve mostrar: Python 3.11.x ou superior

# 2. Git
git --version
# Deve mostrar: git version 2.x

# 3. Conda (se estiver usando)
conda --version
```

### Estrutura de DiretÃ³rios

Verifique se vocÃª estÃ¡ no diretÃ³rio correto:

```bash
# Mostrar diretÃ³rio atual
pwd
# Deve mostrar algo como: /home/seu-usuario/202511-Gravidas

# Listar arquivos principais
ls -la
# Deve mostrar: scripts/, config/, data/, .env, etc.
```

---

## ğŸš€ Passo 1: Atualizar o CÃ³digo

### 1.1 Garantir Ãšltima VersÃ£o

```bash
# Mudar para a branch correta
git checkout claude/synthetic-gravidas-pipeline-011CUpt3YLnLffQE1REgHQoh

# Puxar Ãºltimas atualizaÃ§Ãµes
git pull origin claude/synthetic-gravidas-pipeline-011CUpt3YLnLffQE1REgHQoh
```

**SaÃ­da esperada:**
```
Already on 'claude/synthetic-gravidas-pipeline-011CUpt3YLnLffQE1REgHQoh'
Already up to date.
```

### 1.2 Verificar Scripts DisponÃ­veis

```bash
# Listar scripts
ls -lh scripts/

# Verificar scripts essenciais
ls scripts/01b_generate_personas.py
ls scripts/02_generate_health_records.py
ls scripts/03_match_personas_records_enhanced.py
ls scripts/04_conduct_interviews.py
ls scripts/analyze_interviews.py
```

**Todos devem existir!**

---

## ğŸ”‘ Passo 2: Configurar API Keys

### 2.1 Verificar Arquivo .env

```bash
# Verificar se .env existe
cat .env
```

**Deve mostrar:**
```bash
ANTHROPIC_API_KEY=sk-ant-api03-xxxxx
OPENAI_API_KEY=sk-proj-xxxxx
GOOGLE_API_KEY=AIzaSyxxxxx
```

### 2.2 Testar ConexÃ£o com API

```bash
# Criar script de teste rÃ¡pido
python3 << 'EOF'
import os
from dotenv import load_dotenv

load_dotenv()

api_key = os.getenv('ANTHROPIC_API_KEY')
if api_key and not api_key.startswith('your-'):
    print(f"âœ… API Key encontrada: {api_key[:20]}...")
else:
    print("âŒ API Key nÃ£o configurada!")
EOF
```

**SaÃ­da esperada:**
```
âœ… API Key encontrada: sk-ant-api03-0M7wR...
```

---

## ğŸ“¦ Passo 3: Preparar Ambiente

### 3.1 Criar DiretÃ³rios NecessÃ¡rios

```bash
# Criar todos os diretÃ³rios de dados
mkdir -p data/personas
mkdir -p data/health_records
mkdir -p data/matched
mkdir -p data/interviews
mkdir -p data/analysis
mkdir -p logs

# Verificar criaÃ§Ã£o
ls -la data/
```

**SaÃ­da esperada:**
```
drwxr-xr-x  2 user user 4096 Nov  6 10:00 analysis
drwxr-xr-x  2 user user 4096 Nov  6 10:00 health_records
drwxr-xr-x  2 user user 4096 Nov  6 10:00 interviews
drwxr-xr-x  2 user user 4096 Nov  6 10:00 matched
drwxr-xr-x  2 user user 4096 Nov  6 10:00 personas
```

### 3.2 Limpar Dados Antigos (Opcional)

```bash
# Se vocÃª quer comeÃ§ar totalmente do zero:
rm -f data/personas/*.json
rm -f data/health_records/*.json
rm -f data/matched/*.json
rm -f data/interviews/*.json
rm -f data/analysis/*.csv
rm -f logs/*.log

echo "âœ… Ambiente limpo e pronto!"
```

---

## ğŸ­ Passo 4: Gerar Personas (TESTE PEQUENO)

### 4.1 Teste MÃ­nimo: 10 Personas

**âš ï¸ IMPORTANTE:** Vamos comeÃ§ar com apenas 10 personas para testar rÃ¡pido!

```bash
# Gerar 10 personas para teste
python scripts/01b_generate_personas.py --count 10

# Tempo: ~1-2 minutos
# Custo: ~$0.10
```

**SaÃ­da esperada:**
```
[INFO] === Synthetic Persona Generation Started ===
[INFO] Target: 10 personas
[INFO] Batch size: 100
[INFO] [Batch 1/1] Generating 10 personas...
[INFO]   âœ… Generated 10 valid personas (total: 10)
[INFO] âœ… Saved 10 personas to data/personas/personas.json
[INFO] âœ… Saved summary statistics to data/personas/personas_summary.json
[INFO] [SUCCESS] Generated 10 personas
[INFO] === Persona Generation Completed ===
```

### 4.2 Verificar Personas Geradas

```bash
# Verificar arquivo criado
ls -lh data/personas/personas.json

# Ver quantas personas foram geradas
python3 << 'EOF'
import json
with open('data/personas/personas.json', 'r') as f:
    personas = json.load(f)
print(f"âœ… Total de personas: {len(personas)}")
print(f"\nPrimeira persona:")
print(f"  - ID: {personas[0]['id']}")
print(f"  - Idade: {personas[0]['age']}")
print(f"  - EducaÃ§Ã£o: {personas[0]['education']}")
print(f"  - Estado civil: {personas[0]['marital_status']}")
print(f"  - DescriÃ§Ã£o: {personas[0]['description'][:100]}...")
EOF
```

**SaÃ­da esperada:**
```
âœ… Total de personas: 10

Primeira persona:
  - ID: 1
  - Idade: 28
  - EducaÃ§Ã£o: bachelors
  - Estado civil: married
  - DescriÃ§Ã£o: Sarah is a 28-year-old elementary school teacher living in Boston. She has a bachelor'...
```

### 4.3 Ver DistribuiÃ§Ãµes

```bash
# Ver resumo estatÃ­stico
cat data/personas/personas_summary.json | python -m json.tool
```

**SaÃ­da esperada:**
```json
{
  "total_count": 10,
  "generation_method": "AI-generated (Claude)",
  "age_distribution": {
    "20-29": 4,
    "30-39": 3,
    "40-49": 2,
    "50-59": 1
  },
  "education_distribution": {
    "bachelors": 5,
    "masters": 3,
    "high_school": 2
  },
  ...
}
```

---

## ğŸ¥ Passo 5: Gerar Registros de SaÃºde

### 5.1 Verificar Synthea

```bash
# Verificar se Synthea existe
ls -la synthea/

# Se nÃ£o existir, vocÃª precisa baixar:
# Ver instruÃ§Ãµes em README.md
```

### 5.2 Gerar 10 Registros (Matching com 10 Personas)

```bash
# Gerar 10 registros de saÃºde
python scripts/02_generate_health_records.py --count 10

# Tempo: ~5-10 minutos
# Custo: GrÃ¡tis (Synthea Ã© local)
```

**SaÃ­da esperada:**
```
[INFO] === Health Record Generation Started ===
[INFO] Generating 10 pregnancy-related health records
[INFO] Running Synthea...
[INFO] Synthea output: ...
[INFO] Processing FHIR records...
[INFO] âœ… Processed 10 health records
[INFO] âœ… Saved to data/health_records/health_records.json
[INFO] [SUCCESS] Generated 10 health records
[INFO] === Health Record Generation Completed ===
```

### 5.3 Verificar Registros Gerados

```bash
# Verificar arquivo criado
ls -lh data/health_records/health_records.json

# Ver primeiro registro
python3 << 'EOF'
import json
with open('data/health_records/health_records.json', 'r') as f:
    records = json.load(f)

print(f"âœ… Total de registros: {len(records)}")
print(f"\nPrimeiro registro:")
r = records[0]
print(f"  - Patient ID: {r['patient_id']}")
print(f"  - Idade: {r['age']}")
print(f"  - CondiÃ§Ãµes: {len(r['conditions'])}")
print(f"  - MedicaÃ§Ãµes: {len(r['medications'])}")
print(f"  - ObservaÃ§Ãµes: {len(r['observations'])}")

# Mostrar primeira condiÃ§Ã£o
if r['conditions']:
    print(f"\n  Primeira condiÃ§Ã£o:")
    print(f"    - {r['conditions'][0]['display']}")
    print(f"    - Onset: {r['conditions'][0]['onset']}")
EOF
```

**SaÃ­da esperada:**
```
âœ… Total de registros: 10

Primeiro registro:
  - Patient ID: patient-1
  - Idade: 28
  - CondiÃ§Ãµes: 2
  - MedicaÃ§Ãµes: 1
  - ObservaÃ§Ãµes: 15

  Primeira condiÃ§Ã£o:
    - Pregnancy
    - Onset: 2024-01-15
```

---

## ğŸ”— Passo 6: Fazer Matching Enhanced

### 6.1 Executar Matching

```bash
# Fazer matching otimizado (Algoritmo HÃºngaro)
python scripts/03_match_personas_records_enhanced.py

# Tempo: ~5 segundos (para 10x10)
# Custo: GrÃ¡tis
```

**SaÃ­da esperada:**
```
[INFO] ============================================================
[INFO] ENHANCED PERSONA-RECORD MATCHING STARTED
[INFO] ============================================================
[INFO] âœ… Loaded 10 personas
[INFO] âœ… Loaded 10 health records
[INFO] Computing compatibility matrix for 10 personas Ã— 10 records...
[INFO] Using weights: {'age': 0.4, 'education': 0.2, 'income': 0.15, 'marital_status': 0.15, 'occupation': 0.1}
[INFO] âœ… Compatibility matrix computed
[INFO] Running enhanced matching algorithm...
[INFO] âœ… Created 10 optimal matches
[INFO] Quality distribution:
[INFO]   - Excellent (â‰¥0.85): X (X%)
[INFO]   - Good (â‰¥0.75): X (X%)
[INFO]   - Fair (â‰¥0.65): X (X%)
[INFO]   - Poor (<0.65): X (X%)
[INFO] âœ… ENHANCED MATCHING COMPLETED SUCCESSFULLY
```

### 6.2 Analisar Qualidade do Matching

```bash
# Ver estatÃ­sticas detalhadas
cat data/matched/matching_statistics.json | python -m json.tool
```

**SaÃ­da esperada:**
```json
{
  "total_matches": 10,
  "compatibility_scores": {
    "average": 0.89,
    "median": 0.91,
    "min": 0.75,
    "max": 0.96
  },
  "quality_distribution": {
    "excellent": 8,
    "excellent_pct": 80.0,
    "good": 2,
    "good_pct": 20.0
  },
  "age_differences": {
    "average": 1.2,
    "within_2_years": 9,
    "within_2_years_pct": 90.0
  }
}
```

### 6.3 Ver Matches Individuais

```bash
# Ver primeiros 3 matches com qualidade
python3 << 'EOF'
import json

with open('data/matched/match_quality_metrics.json', 'r') as f:
    metrics = json.load(f)

print("ğŸ¯ Top 3 Matches:\n")
for i, m in enumerate(metrics[:3], 1):
    print(f"{i}. Persona #{m['persona_idx']} â†” Record #{m['record_idx']}")
    print(f"   Score: {m['compatibility_score']:.3f} ({m['quality_category']})")
    print(f"   Idade: {m['persona_age']} vs {m['record_age']} (diff: {m['age_difference']})")
    print(f"   Breakdown:")
    for component, score in m['score_breakdown'].items():
        print(f"     - {component}: {score:.3f}")
    print()
EOF
```

**SaÃ­da esperada:**
```
ğŸ¯ Top 3 Matches:

1. Persona #0 â†” Record #0
   Score: 0.952 (excellent)
   Idade: 28 vs 28 (diff: 0)
   Breakdown:
     - age: 1.000
     - education: 0.880
     - income: 0.950
     - marital_status: 1.000
     - occupation: 0.900

2. Persona #1 â†” Record #1
   Score: 0.915 (excellent)
   ...
```

---

## ğŸ¤ Passo 7: Conduzir Entrevistas (TESTE)

### 7.1 Teste com 1 Entrevista Primeiro

```bash
# Fazer UMA entrevista para testar
python scripts/04_conduct_interviews.py --count 1

# Tempo: ~1-2 minutos
# Custo: ~$0.37
```

**SaÃ­da esperada:**
```
[INFO] === Interview Script Started ===
[INFO] Loaded 10 matched persona-record pairs
[INFO] Will conduct 1 interviews
[INFO] Using provider: anthropic (model: claude-sonnet-4-5-20250929)
[INFO]
[INFO] [1/1] Interviewing Persona #1 (age 28)...
[INFO]   Turn 1/34...
[INFO]   Turn 10/34...
[INFO]   Turn 20/34...
[INFO]   Turn 30/34...
[INFO]   Turn 34/34...
[INFO]   âœ… Interview completed (34 turns, 18,672 words)
[INFO]   Cost: $0.37 (25,206 tokens)
[INFO]
[INFO] âœ… Completed 1 interviews
[INFO] Total cost: $0.37
[INFO] === Interview Script Completed ===
```

### 7.2 Verificar Entrevista Gerada

```bash
# Listar entrevistas
ls -lh data/interviews/

# Ver estrutura da entrevista
python3 << 'EOF'
import json

# Listar arquivos de entrevista
import os
interviews = [f for f in os.listdir('data/interviews') if f.endswith('.json')]

if interviews:
    with open(f'data/interviews/{interviews[0]}', 'r') as f:
        interview = json.load(f)

    print(f"ğŸ“„ Entrevista: {interviews[0]}")
    print(f"\nğŸ“Š InformaÃ§Ãµes:")
    print(f"  - Persona ID: {interview['persona_id']}")
    print(f"  - Idade da persona: {interview['persona_age']}")
    print(f"  - Patient ID (Synthea): {interview['synthea_patient_id']}")
    print(f"  - Total de turnos: {interview['metadata']['total_turns']}")
    print(f"  - Match quality: {interview['match_quality']['compatibility_score']:.3f}")
    print(f"  - Quality category: {interview['match_quality']['quality_category']}")

    print(f"\nğŸ’¬ Primeiras 3 falas:")
    for i, turn in enumerate(interview['transcript'][:3], 1):
        speaker = turn['speaker']
        text = turn['text'][:100]
        print(f"  {i}. {speaker}: {text}...")
else:
    print("âŒ Nenhuma entrevista encontrada!")
EOF
```

**SaÃ­da esperada:**
```
ğŸ“„ Entrevista: interview_00000.json

ğŸ“Š InformaÃ§Ãµes:
  - Persona ID: 1
  - Idade da persona: 28
  - Patient ID (Synthea): patient-1
  - Total de turnos: 34
  - Match quality: 0.952
  - Quality category: excellent

ğŸ’¬ Primeiras 3 falas:
  1. Interviewer: Hello! Thank you for joining me today. I'd like to learn about your pregnancy...
  2. Persona: Hi! Thank you for having me. I'm Sarah, 28 years old, and I'm currently 34 weeks...
  3. Interviewer: That's wonderful, Sarah. How have you been feeling during your pregnancy?...
```

### 7.3 Se 1 Entrevista Funcionou: Fazer 10!

```bash
# Agora fazer 10 entrevistas completas
python scripts/04_conduct_interviews.py --count 10

# Tempo: ~15-20 minutos
# Custo: ~$3.70 (10 Ã— $0.37)
```

**ObservaÃ§Ãµes durante execuÃ§Ã£o:**
- VocÃª verÃ¡ progresso em tempo real
- Cada entrevista leva ~1-2 minutos
- Custo total serÃ¡ mostrado no final

---

## ğŸ“Š Passo 8: Analisar Resultados

### 8.1 Executar AnÃ¡lise

```bash
# Analisar todas as entrevistas geradas
python scripts/analyze_interviews.py

# Tempo: ~10 segundos
# Custo: GrÃ¡tis
```

**SaÃ­da esperada:**
```
[INFO] Analyzing interviews from data/interviews
[INFO] Found 10 interview files
[INFO] Processing interviews...
[INFO] âœ… Analyzed 10 interviews
[INFO] âœ… Saved summary to data/analysis/interview_summary.csv
[INFO]
[INFO] Summary Statistics:
[INFO]   - Total interviews: 10
[INFO]   - Average turns: 34
[INFO]   - Average words: 18,500
[INFO]   - Average cost: $0.37
[INFO]   - Total cost: $3.70
```

### 8.2 Ver CSV de Resultados

```bash
# Ver primeiras linhas do CSV
head -5 data/analysis/interview_summary.csv | column -t -s,
```

**Ou visualizar melhor:**

```bash
# Usar Python para ver formatado
python3 << 'EOF'
import pandas as pd

df = pd.read_csv('data/analysis/interview_summary.csv')

print("ğŸ“Š Resumo das Entrevistas:\n")
print(f"Total de entrevistas: {len(df)}")
print(f"\nğŸ“ˆ EstatÃ­sticas:")
print(f"  - Idade mÃ©dia: {df['persona_age'].mean():.1f} anos")
print(f"  - Turnos mÃ©dios: {df['total_turns'].mean():.1f}")
print(f"  - Palavras mÃ©dias: {df['total_words'].mean():.0f}")
print(f"  - Custo mÃ©dio: ${df['cost_usd'].mean():.2f}")
print(f"  - Custo total: ${df['cost_usd'].sum():.2f}")

print(f"\nğŸ¯ Qualidade dos Matches:")
print(df[['persona_id', 'persona_age', 'match_quality_score', 'match_quality_category']].to_string(index=False))

print(f"\nğŸ’° Custos por entrevista:")
print(df[['persona_id', 'total_turns', 'cost_usd']].to_string(index=False))
EOF
```

**SaÃ­da esperada:**
```
ğŸ“Š Resumo das Entrevistas:

Total de entrevistas: 10

ğŸ“ˆ EstatÃ­sticas:
  - Idade mÃ©dia: 32.5 anos
  - Turnos mÃ©dios: 34.2
  - Palavras mÃ©dias: 18,450
  - Custo mÃ©dio: $0.37
  - Custo total: $3.70

ğŸ¯ Qualidade dos Matches:
persona_id  persona_age  match_quality_score  match_quality_category
         1           28                0.952               excellent
         2           35                0.915               excellent
         3           29                0.890               excellent
       ...

ğŸ’° Custos por entrevista:
persona_id  total_turns  cost_usd
         1           34      0.37
         2           35      0.38
         3           33      0.36
       ...
```

---

## ğŸ¯ Passo 9: ValidaÃ§Ã£o Final

### 9.1 Checklist de Sucesso

Execute este script final para validar tudo:

```bash
python3 << 'EOF'
import json
import os
from pathlib import Path

print("=" * 60)
print("ğŸ” VALIDAÃ‡ÃƒO FINAL DO PIPELINE")
print("=" * 60)

checks = []

# 1. Personas
if Path('data/personas/personas.json').exists():
    with open('data/personas/personas.json', 'r') as f:
        personas = json.load(f)
    checks.append(("âœ…", f"Personas geradas: {len(personas)}"))
else:
    checks.append(("âŒ", "Personas NÃƒO encontradas"))

# 2. Health Records
if Path('data/health_records/health_records.json').exists():
    with open('data/health_records/health_records.json', 'r') as f:
        records = json.load(f)
    checks.append(("âœ…", f"Health records gerados: {len(records)}"))
else:
    checks.append(("âŒ", "Health records NÃƒO encontrados"))

# 3. Matched Pairs
if Path('data/matched/matched_personas.json').exists():
    with open('data/matched/matched_personas.json', 'r') as f:
        matches = json.load(f)
    checks.append(("âœ…", f"Matches criados: {len(matches)}"))
else:
    checks.append(("âŒ", "Matches NÃƒO encontrados"))

# 4. Quality Metrics
if Path('data/matched/matching_statistics.json').exists():
    with open('data/matched/matching_statistics.json', 'r') as f:
        stats = json.load(f)
    avg_score = stats['compatibility_scores']['average']
    checks.append(("âœ…", f"Score mÃ©dio de matching: {avg_score:.3f}"))
else:
    checks.append(("âš ï¸", "EstatÃ­sticas de matching nÃ£o encontradas"))

# 5. Interviews
interview_files = list(Path('data/interviews').glob('interview_*.json'))
if interview_files:
    checks.append(("âœ…", f"Entrevistas realizadas: {len(interview_files)}"))
else:
    checks.append(("âŒ", "Entrevistas NÃƒO encontradas"))

# 6. Analysis
if Path('data/analysis/interview_summary.csv').exists():
    import pandas as pd
    df = pd.read_csv('data/analysis/interview_summary.csv')
    total_cost = df['cost_usd'].sum()
    checks.append(("âœ…", f"AnÃ¡lise completa - Custo total: ${total_cost:.2f}"))
else:
    checks.append(("âŒ", "AnÃ¡lise NÃƒO encontrada"))

# Mostrar resultados
print("\nğŸ“‹ Resultados:\n")
for status, message in checks:
    print(f"  {status} {message}")

# Contabilizar
success = sum(1 for s, _ in checks if s == "âœ…")
total = len(checks)

print("\n" + "=" * 60)
print(f"ğŸ¯ RESULTADO: {success}/{total} etapas completadas")
print("=" * 60)

if success == total:
    print("\nğŸ‰ SUCESSO COMPLETO! Pipeline funcionando perfeitamente!")
    print("\nâœ¨ PrÃ³ximos passos:")
    print("  1. Revisar qualidade das entrevistas")
    print("  2. Ajustar parÃ¢metros se necessÃ¡rio")
    print("  3. Escalar para 100, 1000, ou 10000 entrevistas!")
elif success >= total - 1:
    print("\nâœ… Quase lÃ¡! Pipeline estÃ¡ 95% funcional.")
    print("   Revise os itens pendentes acima.")
else:
    print("\nâš ï¸  Alguns problemas encontrados.")
    print("   Revise os erros acima e reexecute os passos faltantes.")
EOF
```

**SaÃ­da esperada (sucesso completo):**
```
============================================================
ğŸ” VALIDAÃ‡ÃƒO FINAL DO PIPELINE
============================================================

ğŸ“‹ Resultados:

  âœ… Personas geradas: 10
  âœ… Health records gerados: 10
  âœ… Matches criados: 10
  âœ… Score mÃ©dio de matching: 0.915
  âœ… Entrevistas realizadas: 10
  âœ… AnÃ¡lise completa - Custo total: $3.70

============================================================
ğŸ¯ RESULTADO: 6/6 etapas completadas
============================================================

ğŸ‰ SUCESSO COMPLETO! Pipeline funcionando perfeitamente!

âœ¨ PrÃ³ximos passos:
  1. Revisar qualidade das entrevistas
  2. Ajustar parÃ¢metros se necessÃ¡rio
  3. Escalar para 100, 1000, ou 10000 entrevistas!
```

---

## ğŸ“ Estrutura Final de Arquivos

ApÃ³s completar o tutorial, vocÃª terÃ¡:

```
202511-Gravidas/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ personas/
â”‚   â”‚   â”œâ”€â”€ personas.json (10 personas)
â”‚   â”‚   â””â”€â”€ personas_summary.json
â”‚   â”œâ”€â”€ health_records/
â”‚   â”‚   â””â”€â”€ health_records.json (10 registros)
â”‚   â”œâ”€â”€ matched/
â”‚   â”‚   â”œâ”€â”€ matched_personas.json (10 pares)
â”‚   â”‚   â”œâ”€â”€ match_quality_metrics.json
â”‚   â”‚   â””â”€â”€ matching_statistics.json
â”‚   â”œâ”€â”€ interviews/
â”‚   â”‚   â”œâ”€â”€ interview_00000.json
â”‚   â”‚   â”œâ”€â”€ interview_00001.json
â”‚   â”‚   â””â”€â”€ ... (10 arquivos)
â”‚   â””â”€â”€ analysis/
â”‚       â””â”€â”€ interview_summary.csv
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ 01b_generate_personas.log
â”‚   â”œâ”€â”€ 02_generate_health_records.log
â”‚   â”œâ”€â”€ 03_match_personas_records_enhanced.log
â”‚   â””â”€â”€ 04_conduct_interviews.log
â””â”€â”€ ...
```

---

## ğŸ“ PrÃ³ximos Passos

### OpÃ§Ã£o 1: Revisar Qualidade

```bash
# Ler uma entrevista completa
cat data/interviews/interview_00000.json | python -m json.tool | less

# Ver anÃ¡lise detalhada
cat data/analysis/interview_summary.csv
```

### OpÃ§Ã£o 2: Escalar Gradualmente

```bash
# Escalar para 100 personas
python scripts/01b_generate_personas.py --count 100
python scripts/02_generate_health_records.py --count 100
python scripts/03_match_personas_records_enhanced.py
python scripts/04_conduct_interviews.py --count 100

# Custo esperado: ~$37
# Tempo: ~2-3 horas
```

### OpÃ§Ã£o 3: Ajustar ParÃ¢metros

**Modificar qualidade do matching:**
```bash
# Editar scripts/03_match_personas_records_enhanced.py
# Ajustar pesos na linha ~250:
weights = {
    'age': 0.50,            # Aumentar importÃ¢ncia da idade
    'education': 0.15,      # Reduzir educaÃ§Ã£o
    'income': 0.15,
    'marital_status': 0.15,
    'occupation': 0.05
}
```

**Mudar modelo de AI:**
```bash
# Editar config/config.yaml
active_model: "claude-3-haiku"  # Mais barato ($0.10/interview)
# ou
active_model: "claude-4.1-opus"  # Mais caro mas melhor qualidade
```

### OpÃ§Ã£o 4: ProduÃ§Ã£o Completa

```bash
# Pipeline completo: 20K personas â†’ 10K registros â†’ 10K entrevistas

# 1. Gerar 20K personas (2-3 horas, $20-40)
python scripts/01b_generate_personas.py --count 20000

# 2. Gerar 10K registros (30-60 min, grÃ¡tis)
python scripts/02_generate_health_records.py --count 10000

# 3. Matching enhanced (5-15 min, grÃ¡tis)
python scripts/03_match_personas_records_enhanced.py

# 4. Entrevistas (6 dias ou usar batch API, $3,700 ou $1,870)
python scripts/04_conduct_interviews.py --count 10000
# OU com batch mode (50% desconto):
python scripts/04_conduct_interviews.py --count 10000 --batch-mode

# 5. AnÃ¡lise final
python scripts/analyze_interviews.py
```

---

## ğŸ› Troubleshooting

### Problema: "API key not found"

```bash
# Verificar .env
cat .env | grep ANTHROPIC

# Recarregar
source .env

# Testar
python3 -c "import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('ANTHROPIC_API_KEY'))"
```

### Problema: "No module named 'anthropic'"

```bash
# Instalar dependÃªncias
pip install -r requirements.txt

# Ou individualmente
pip install anthropic openai google-generativeai python-dotenv pyyaml
```

### Problema: "Synthea not found"

```bash
# Baixar Synthea
# Ver README.md para instruÃ§Ãµes

# Ou verificar caminho
ls -la synthea/
```

### Problema: "Low match quality scores"

```bash
# Regenerar personas com mais diversidade
python scripts/01b_generate_personas.py --count 50

# Ou ajustar pesos de matching
# Editar scripts/03_match_personas_records_enhanced.py
```

---

## ğŸ“Š MÃ©tricas de Sucesso

**VocÃª terÃ¡ sucesso se:**

âœ… **Todas as 6 etapas completadas** (personas, records, matching, interviews, analysis)
âœ… **Score mÃ©dio de matching > 0.80** (bom) ou **> 0.85** (excelente)
âœ… **80%+ matches excellent/good** na distribuiÃ§Ã£o de qualidade
âœ… **Entrevistas naturais e coerentes** ao revisar manualmente
âœ… **Custo dentro do esperado** (~$0.37 por entrevista com Claude Sonnet)

**Benchmarks:**
- 10 entrevistas: $3.70, 30 minutos
- 100 entrevistas: $37, 2-3 horas
- 1,000 entrevistas: $370, 15 horas
- 10,000 entrevistas: $3,700, 6 dias (ou $1,870 com batch)

---

## ğŸ‰ ConclusÃ£o

ParabÃ©ns! Se vocÃª chegou atÃ© aqui, vocÃª testou com sucesso todo o pipeline:

1. âœ… **GeraÃ§Ã£o de personas** com AI
2. âœ… **GeraÃ§Ã£o de health records** com Synthea
3. âœ… **Matching otimizado** com Algoritmo HÃºngaro
4. âœ… **Entrevistas** com Claude
5. âœ… **AnÃ¡lise** de resultados

**Pipeline estÃ¡ pronto para produÃ§Ã£o!** ğŸš€

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- `QUICK_START.md` - Comandos rÃ¡pidos
- `TUTORIAL_ENHANCED_MATCHING.md` - Tutorial detalhado do matching
- `docs/ALGORITMO_HUNGARO.md` - ExplicaÃ§Ã£o do algoritmo em portuguÃªs
- `README.md` - VisÃ£o geral do projeto

---

*Tutorial criado para 202511-Gravidas Pipeline*
*Ãšltima atualizaÃ§Ã£o: 2025-11-06*
*Testado com Python 3.11, Claude Sonnet 4.5*
